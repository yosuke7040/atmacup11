{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "activated-charge",
   "metadata": {},
   "source": [
    "## 講座1_シンプルバージョンをベースにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resistant-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import  glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romantic-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/src/atmacup/atmacup11/data/inputs/'\n",
    "photo_dir = os.path.join(input_dir, 'photos')\n",
    "photo_pathes = glob(os.path.join(photo_dir, \"*.jpg\"))\n",
    "output_dir = '/src/atmacup/atmacup11/data/outputs/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n",
    "\n",
    "material_df = pd.read_csv(os.path.join(input_dir, 'materials.csv'))\n",
    "technique_df = pd.read_csv(os.path.join(input_dir, 'techniques.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optional-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#pip install ipynb-path\n",
    "import ipynb_path\n",
    "\n",
    "class Config:\n",
    "    N_FOLDS = 5\n",
    "    N_EPOCHS = 1\n",
    "    NB_NAME = ''.join(re.findall('.*/(.*).ipynb', ipynb_path.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-vegetarian",
   "metadata": {},
   "source": [
    "### 画像データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beautiful-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def to_img_path(object_id):\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "positive-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils import data\n",
    "\n",
    "# torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "olive-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "    \n",
    "    @property\n",
    "    def meta_keys(self):\n",
    "        retbal = [self.object_path_key]\n",
    "        \n",
    "        if self.is_train:\n",
    "            retbal += [self.label_key]\n",
    "            \n",
    "        return retbal\n",
    "    \n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            meta_df: \n",
    "                画像へのパスと label 情報が含まれている dataframe\n",
    "                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n",
    "            \n",
    "            is_train:\n",
    "                True のとき学習用のデータ拡張を適用します.\n",
    "                False の時は単に size にリサイズを行います\n",
    "        \"\"\"\n",
    "        \n",
    "        self.is_train = is_train\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(\"meta df muust have {}\".format(k))\n",
    "        \n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (224, 224)\n",
    "        \n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = Image.open(obj_path)\n",
    "        img = self.transformer(img)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reverse-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-westminster",
   "metadata": {},
   "source": [
    "## Train / Validation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    train_loader: data.DataLoader\n",
    ") -> pd.Series:\n",
    "    \n",
    "    # train にすることで model 内の学習時にのみ有効な機構が有効になります (Dropouts Layers、BatchNorm Layers\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i, (x_i, y_i) in enumerate(train_loader):\n",
    "        x_i = x_i.to(DEVICE)\n",
    "        y_i = y_i.to(DEVICE).reshape(-1,1).float()\n",
    "        \n",
    "        output = model(x_i)\n",
    "        loss = criterion(output, y_i)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n",
    "    # train とは逆で model 内の学習時にのみ有効な機構がオフになります (Dropouts Layers、BatchNorm Layers...)\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    \n",
    "    for x_i, y_i in loader:\n",
    "        \n",
    "        # 明示的に勾配を計算しないように指定することができます. \n",
    "        # この関数ではモデルの更新はせずに単に出力だけを使いますので勾配は不要です.\n",
    "        with torch.no_grad():\n",
    "            output = model(x_i.to(DEVICE))\n",
    "            \n",
    "        predicts.extend(output.data.cpu().numpy())\n",
    "        \n",
    "    pred = np.array(predicts).reshape(-1)\n",
    "    return pred\n",
    "\n",
    "def calculate_metrics(y_true, y_pred) -> dict:\n",
    "    \"\"\"正解ラベルと予測ラベルから指標を計算する\"\"\"    \n",
    "    return {\n",
    "        'rmse': mean_squared_error(y_true, y_pred) ** .5\n",
    "    }\n",
    "\n",
    "def valid(\n",
    "    model: nn.Module, \n",
    "    y_valid: np.ndarray, \n",
    "    valid_loader: data.DataLoader\n",
    ") -> pd.Series:\n",
    "    \"\"\"検証フェーズ\n",
    "    与えられたモデル・データローダを使って検証フェーズを実行。スコアの dict と予測した値を返す\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = predict(model, valid_loader)\n",
    "    print(f'y_valid={y_valid.shape} pred={pred.shape}')\n",
    "    score = calculate_metrics(y_valid, pred)\n",
    "    return score, pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-proportion",
   "metadata": {},
   "source": [
    "## Run Fold\n",
    "\n",
    "1. train / valid の loader 作成\n",
    "2. 以下を epoch 数だけ繰り返す\n",
    "    1. 学習用データで学習 \n",
    "    2. 検証用データで検証スコアの算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "guided-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(\n",
    "    model: nn.Module, \n",
    "    train_df: pd.DataFrame, \n",
    "    valid_df: pd.DataFrame, \n",
    "    y_valid: np.ndarray, \n",
    "    n_epochs=30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    train / valid に分割されたデータで学習と同時に検証を行なう\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0: \n",
    "    #   : 前準備. dataframe から data loader を作成\n",
    "    train_dataset = AtmaDataset(meta_df=train_df)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4\n",
    "    )\n",
    "    \n",
    "    #   : 検証用の方は is_train=False にしてデータ拡張オフにする\n",
    "    valid_dataset = AtmaDataset(meta_df=valid_df, is_train=False)\n",
    "    valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=4)\n",
    "    \n",
    "    # optimizer の定義\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f'start {epoch}')\n",
    "        \n",
    "        # 1: 学習用データで学習を実行。学習時のロスを取得\n",
    "        train(model, optimizer, train_loader)\n",
    "        \n",
    "        # 2: 検証データでのスコアを計算\n",
    "        score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid=y_valid)\n",
    "        \n",
    "        print(score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-investor",
   "metadata": {},
   "source": [
    "### その他\n",
    "\n",
    "モデル作成などの関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "renewable-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "    return model\n",
    "\n",
    "def create_metadata(input_df):\n",
    "    out_df = input_df[['object_id']].copy()\n",
    "    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n",
    "    \n",
    "    if \"target\" in input_df:\n",
    "        out_df[\"target\"] = input_df[\"target\"]\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "def run_test_predict(model):\n",
    "    test_meta_df = create_metadata(test_df)\n",
    "    \n",
    "    test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)\n",
    "    \n",
    "    y_pred = predict(model, loader=test_loader)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "architectural-wholesale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== start cv 0 ====\n",
      "start 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9288ae6d9197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mvalid_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_meta_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_meta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-437fd604e82c>\u001b[0m in \u001b[0;36mrun_fold\u001b[0;34m(model, train_df, valid_df, y_valid, n_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# 1: 学習用データで学習を実行。学習時のロスを取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# 2: 検証データでのスコアを計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5438911e187a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_meta_df = create_metadata(train_df)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "fold = KFold(n_splits=5, shuffle=True, random_state=510)\n",
    "cv = list(fold.split(X=train_df, y=train_df['target']))[:Config.N_FOLDS]\n",
    "\n",
    "for i, (idx_tr, idx_valid) in enumerate(cv):\n",
    "    print(f'==== start cv {i} ====')\n",
    "    model = create_model()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 1. Fold の学習\n",
    "    run_fold(\n",
    "        model=model, \n",
    "        train_df=train_meta_df.iloc[idx_tr], \n",
    "        valid_df=train_meta_df.iloc[idx_valid], \n",
    "        y_valid=train_meta_df['target'].values[idx_valid],\n",
    "        n_epochs=Config.N_EPOCHS\n",
    "    )\n",
    "    \n",
    "    # 2. モデルで予測 (本当はローカルに保存した重みを読みだすなどするほうがあとで振り返りやすいが簡易にそのまま予測する)\n",
    "    y_pred_i = run_test_predict(model)\n",
    "    test_predictions.append(y_pred_i)\n",
    "    del model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべての予測の平均値を使う\n",
    "pred_mean = np.array(test_predictions).mean(axis=0)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"target\": pred_mean\n",
    "}).to_csv(os.path.join(output_dir, Config.NB_NAME + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-edmonton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-heather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-prime",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-concentration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-trade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-young",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
