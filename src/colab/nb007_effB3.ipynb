{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"nb007_effB3.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"opposed-poverty"},"source":["## SimSiamの写経  \n","https://www.guruguru.science/competitions/17/discussions/a39d588e-aff2-4728-8323-b07f15563552/"],"id":"opposed-poverty"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uigVB7sUwi2z","executionInfo":{"status":"ok","timestamp":1626870803268,"user_tz":-540,"elapsed":16100,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"bf1c4187-995f-4bf0-a584-da5fd662418c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"uigVB7sUwi2z","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KUW3c7iYw7I5","executionInfo":{"status":"ok","timestamp":1626870819674,"user_tz":-540,"elapsed":16410,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"e758eef6-9ae1-4419-b51c-0b1631ecb2be"},"source":["!pip install lightly"],"id":"KUW3c7iYw7I5","execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting lightly\n","  Downloading lightly-1.1.15-py3-none-any.whl (240 kB)\n","\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.8.1)\n","Collecting lightly-utils==0.0.1\n","  Downloading lightly_utils-0.0.1-py3-none-any.whl (6.3 kB)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.24.3)\n","Collecting tqdm>=4.44\n","  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightly) (0.10.0+cu102)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.19.5)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (57.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from lightly) (2021.5.30)\n","Collecting pytorch-lightning>=1.0.4\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[K     |████████████████████████████████| 813 kB 14.6 MB/s \n","\u001b[?25hCollecting hydra-core>=1.0.0\n","  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 20.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.23.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lightly-utils==0.0.1->lightly) (7.1.2)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 36.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (5.2.0)\n","Collecting omegaconf==2.1.*\n","  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.*\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 36.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (1.9.0+cu102)\n","Collecting tensorboard!=2.5.0,>=2.2.0\n","  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","\u001b[K     |████████████████████████████████| 10.6 MB 38.9 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 52.4 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Collecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 50.9 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 38.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (21.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 32.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.0.4->lightly) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (3.0.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.36.2)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.17.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.32.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.34.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.3.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.12.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.6.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning>=1.0.4->lightly) (3.7.4.3)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 47.6 MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (21.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 57.3 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.5.0)\n","Building wheels for collected packages: antlr4-python3-runtime, future\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=9c801a613caf97bd2a0025eea2ba8a0978585a9b37428af9cec48f756563801f\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=cdad9a9c24ab4244b501450184bbb8e3e71ca56b871c3dd0ca58a961d5c7bd30\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built antlr4-python3-runtime future\n","Installing collected packages: multidict, yarl, async-timeout, PyYAML, fsspec, antlr4-python3-runtime, aiohttp, tqdm, torchmetrics, tensorboard, pyDeprecate, omegaconf, future, pytorch-lightning, lightly-utils, hydra-core, lightly\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 antlr4-python3-runtime-4.8 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 hydra-core-1.1.0 lightly-1.1.15 lightly-utils-0.0.1 multidict-5.1.0 omegaconf-2.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.8 tensorboard-2.4.1 torchmetrics-0.4.1 tqdm-4.61.2 yarl-1.6.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reported-niger","executionInfo":{"status":"ok","timestamp":1626870819674,"user_tz":-540,"elapsed":8,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"bec6d141-e8d8-4030-e04b-351468578738"},"source":["!nvidia-smi"],"id":"reported-niger","execution_count":3,"outputs":[{"output_type":"stream","text":["Wed Jul 21 12:33:34 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"major-purse","executionInfo":{"status":"ok","timestamp":1626870827482,"user_tz":-540,"elapsed":4523,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import lightly\n","import os"],"id":"major-purse","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"instructional-yesterday","executionInfo":{"status":"ok","timestamp":1626870880073,"user_tz":-540,"elapsed":370,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["num_workers = 2\n","batch_size = 64\n","seed = 1993\n","epochs = 50\n","input_size = 224\n","\n","# dimension of the embeddings\n","num_ftrs = 512\n","# dimension of the output of the prediction and projection heads\n","out_dim = proj_hidden_dim = 512\n","# the prediction head uses a bottleneck architecture\n","#pred_hidden_dim = 128\n","# use 2 layers in the projection head\n","num_mlp_layers = 2"],"id":"instructional-yesterday","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"lasting-addiction","executionInfo":{"status":"ok","timestamp":1626870836763,"user_tz":-540,"elapsed":369,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","\n","input_dir = '/content/drive/MyDrive/Colab Notebooks/atmacup/atmacup11/data/inputs/'\n","path_to_data = os.path.join(input_dir, 'photos')\n","model_dir = '/content/drive/MyDrive/Colab Notebooks/atmacup/atmacup11/data/model/'"],"id":"lasting-addiction","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sapphire-taiwan"},"source":["## DataLoader"],"id":"sapphire-taiwan"},{"cell_type":"code","metadata":{"id":"elegant-lesbian","executionInfo":{"status":"ok","timestamp":1626871363742,"user_tz":-540,"elapsed":46595,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# define the augmentations for self-supervised learning\n","collate_fn = lightly.data.ImageCollateFunction(\n","    input_size=input_size,\n","    # require invariance to flips and rotations\n","    hf_prob=0.5,\n","    vf_prob=0.5,\n","    rr_prob=0.5,\n","    # satellite images are all taken from the same height\n","    # so we use only slight random cropping\n","    min_scale=0.5,\n","    # use a weak color jitter for invariance w.r.t small color changes\n","    cj_prob=0.2,\n","    cj_bright=0.1,\n","    cj_contrast=0.1,\n","    cj_hue=0.1,\n","    cj_sat=0.1,\n",")\n","\n","# create a lightly dataset for training, since the augmentations are handled\n","# by the collate function, there is no need to apply additional ones here\n","dataset_train_simsiam = lightly.data.LightlyDataset(\n","    input_dir=path_to_data\n",")\n","\n","# create a dataloader for training\n","dataloader_train_simsiam = torch.utils.data.DataLoader(\n","    dataset_train_simsiam,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    drop_last=True,\n","    num_workers=num_workers\n",")\n","\n","# create a torchvision transformation for embedding the dataset after training\n","# here, we resize the images to match the input size during training and apply\n","# a normalization of the color channel based on statistics from imagenet\n","test_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((input_size, input_size)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(\n","        mean=lightly.data.collate.imagenet_normalize['mean'],\n","        std=lightly.data.collate.imagenet_normalize['std'],\n","    )\n","])\n","\n","\n","\n","# create a lightly dataset for embedding\n","dataset_test = lightly.data.LightlyDataset(\n","    input_dir=path_to_data,\n","    transform=test_transforms\n",")\n","\n","\n","\n","# create a dataloader for embedding\n","dataloader_test = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")"],"id":"elegant-lesbian","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqGwP63BVhU9","executionInfo":{"status":"ok","timestamp":1626871367469,"user_tz":-540,"elapsed":3734,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"5c12258b-95bd-45dc-b051-3455a84285b9"},"source":["!pip install efficientnet_pytorch"],"id":"eqGwP63BVhU9","execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=acefff47851058cfcee5f603185ebc59d64ba8ebf44f5dd3c6f462f5c9fb69f2\n","  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"equivalent-apollo"},"source":["## Model"],"id":"equivalent-apollo"},{"cell_type":"code","metadata":{"id":"super-understanding","executionInfo":{"status":"ok","timestamp":1626871367882,"user_tz":-540,"elapsed":415,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# we use a pretrained resnet for this tutorial to speed\n","# up training time but you can also train one from scratch\n","# Do not use pretrained Model\n","# resnet = torchvision.models.resnet18(pretrained=False)\n","# backbone = nn.Sequential(*list(resnet.children())[:-1])\n","from efficientnet_pytorch import EfficientNet\n","effB3 = EfficientNet.from_name('efficientnet-b3')\n","backbone = nn.Sequential(*list(effB3.children())[:-3])\n","\n","# create the SimSiam model using the backbone from above\n","model = lightly.models.SimSiam(\n","    backbone,\n","    num_ftrs=num_ftrs,\n","#     proj_hidden_dim=pred_hidden_dim,\n","#     pred_hidden_dim=pred_hidden_dim,\n","#     out_dim=out_dim,\n","    num_mlp_layers=num_mlp_layers\n",")"],"id":"super-understanding","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wc6I9rdGZogs","executionInfo":{"status":"ok","timestamp":1626871367882,"user_tz":-540,"elapsed":2,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["#effB3"],"id":"Wc6I9rdGZogs","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_AeZgI5ZsFE","executionInfo":{"status":"ok","timestamp":1626871369003,"user_tz":-540,"elapsed":1,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["#backbone"],"id":"T_AeZgI5ZsFE","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MkIGFbFaOU8","executionInfo":{"status":"ok","timestamp":1626871370468,"user_tz":-540,"elapsed":2,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["#nn.Sequential(*list(effB3.children())[:-3])"],"id":"9MkIGFbFaOU8","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"1OhQvcCAVm6t","executionInfo":{"status":"ok","timestamp":1626871375292,"user_tz":-540,"elapsed":272,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["#resnet = torchvision.models.resnet18(pretrained=False)\n","#backbone = nn.Sequential(*list(resnet.children())[:-1])\n","#backbone"],"id":"1OhQvcCAVm6t","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Lp3i9voWaeF","executionInfo":{"status":"ok","timestamp":1626871377296,"user_tz":-540,"elapsed":274,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["#resnet"],"id":"6Lp3i9voWaeF","execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"artificial-penguin"},"source":["## Loss / Optimizer"],"id":"artificial-penguin"},{"cell_type":"code","metadata":{"id":"enormous-calendar","executionInfo":{"status":"ok","timestamp":1626871386176,"user_tz":-540,"elapsed":276,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# SimSiam uses a symmetric negative cosine similarity loss\n","criterion = lightly.loss.SymNegCosineSimilarityLoss()\n","\n","# scale the learning rate\n","lr = 0.05 * batch_size / 256\n","# use SGD with momentum and weight decay\n","optimizer = torch.optim.SGD(\n","    model.parameters(),\n","    lr=lr,\n","    momentum=0.9,\n","    weight_decay=5e-4\n",")"],"id":"enormous-calendar","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":974},"id":"above-emission","executionInfo":{"status":"error","timestamp":1626871429443,"user_tz":-540,"elapsed":28262,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"782faa3b-7c5a-4528-f1a8-443b476fb0c6"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","avg_loss = 0.\n","avg_output_std = 0.\n","for e in range(epochs):\n","\n","    for (x0, x1), _, _ in dataloader_train_simsiam:\n","\n","        # move images to the gpu\n","        x0 = x0.to(device)\n","        x1 = x1.to(device)\n","\n","        # run the model on both transforms of the images\n","        # the output of the simsiam model is a y containing the predictions\n","        # and projections for each input x\n","        y0, y1 = model(x0, x1)\n","\n","        # backpropagation\n","        loss = criterion(y0, y1)\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # calculate the per-dimension standard deviation of the outputs\n","        # we can use this later to check whether the embeddings are collapsing\n","        output, _ = y0\n","        output = output.detach()\n","        output = torch.nn.functional.normalize(output, dim=1)\n","\n","        output_std = torch.std(output, 0)\n","        output_std = output_std.mean()\n","\n","        # use moving averages to track the loss and standard deviation\n","        w = 0.9\n","        avg_loss = w * avg_loss + (1 - w) * loss.item()\n","        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n","\n","    # the level of collapse is large if the standard deviation of the l2\n","    # normalized output is much smaller than 1 / sqrt(dim)\n","    collapse_level = max(0., 1 - math.sqrt(out_dim) * avg_output_std)\n","    # print intermediate results\n","    print(f'[Epoch {e:3d}] '\n","        f'Loss = {avg_loss:.2f} | '\n","        f'Collapse Level: {collapse_level:.2f} / 1.00')"],"id":"above-emission","execution_count":17,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-fd8b9b7e3f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# the output of the simsiam model is a y containing the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# and projections for each input x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightly/models/simsiam.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x0, x1, return_features)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"municipal-situation","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626779916086,"user_tz":-540,"elapsed":9,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"a7b35ddc-e948-42ad-d50d-ac056c7b413b"},"source":["from torchsummary import summary\n","summary(model, (3,224,224))"],"id":"municipal-situation","execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                 [-1, 2048]       1,050,624\n","      BatchNorm1d-69                 [-1, 2048]           4,096\n","             ReLU-70                 [-1, 2048]               0\n","           Linear-71                 [-1, 2048]       4,196,352\n","      BatchNorm1d-72                 [-1, 2048]           4,096\n","           Linear-73                  [-1, 512]       1,049,088\n","      BatchNorm1d-74                  [-1, 512]           1,024\n","             ReLU-75                  [-1, 512]               0\n","           Linear-76                 [-1, 2048]       1,050,624\n","================================================================\n","Total params: 18,532,416\n","Trainable params: 18,532,416\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.89\n","Params size (MB): 70.70\n","Estimated Total Size (MB): 134.16\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"expected-magic"},"source":["torch.save(model.state_dict(), os.path.join(model_dir,'simsiam_effB3.pth'))"],"id":"expected-magic","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"circular-discussion"},"source":["test = model.load_state_dict(torch.load(os.path.join(model_dir,'simsiam_effB3.pth')))"],"id":"circular-discussion","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"80-XW7gKwhuZ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"error","timestamp":1626781211567,"user_tz":-540,"elapsed":3,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"6acbdeff-1398-456b-a648-79991092b300"},"source":["from torchsummary import summary\n","#model = resnet18(pretrained=False)\n","resnet = resnet18(pretrained=False)\n","backbone = nn.Sequential(*list(resnet.children())[:-1])\n","model = lightly.models.SimSiam(\n","    backbone,\n","    num_ftrs=num_ftrs,\n","#     proj_hidden_dim=pred_hidden_dim,\n","#     pred_hidden_dim=pred_hidden_dim,\n","#     out_dim=out_dim,\n","    num_mlp_layers=num_mlp_layers\n",")\n","model.load_state_dict(torch.load(os.path.join(model_dir,'simsiam_res18_256.pth')))\n","model = model.backbone\n","model.add_module('flatten', nn.Flatten())\n","model.add_module('fc', nn.Linear(in_features=512, out_features=1, bias=True))\n","DEVICE = torch.device(\"cuda\")\n","model.to(DEVICE)\n","summary(model, (3,224,224))"],"id":"80-XW7gKwhuZ","execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-5f32a8578808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'to'"]}]},{"cell_type":"code","metadata":{"id":"dJHhJ21ptjtd"},"source":[""],"id":"dJHhJ21ptjtd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwMLBunVWWc9"},"source":[""],"id":"RwMLBunVWWc9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSZQuJksWYil"},"source":[""],"id":"tSZQuJksWYil","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5wzlYjoZqrk"},"source":[""],"id":"m5wzlYjoZqrk","execution_count":null,"outputs":[]}]}