{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"nb007.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"opposed-poverty"},"source":["## SimSiamの写経  \n","https://www.guruguru.science/competitions/17/discussions/a39d588e-aff2-4728-8323-b07f15563552/"],"id":"opposed-poverty"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uigVB7sUwi2z","executionInfo":{"status":"ok","timestamp":1626771163546,"user_tz":-540,"elapsed":17105,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"7158a02a-34a4-4c56-fe67-29879925e97d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"uigVB7sUwi2z","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KUW3c7iYw7I5","executionInfo":{"status":"ok","timestamp":1626771179869,"user_tz":-540,"elapsed":16326,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"813a72ca-81d7-4686-beca-3c6e3fdd603c"},"source":["!pip install lightly"],"id":"KUW3c7iYw7I5","execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting lightly\n","  Downloading lightly-1.1.15-py3-none-any.whl (240 kB)\n","\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.8.1)\n","Collecting hydra-core>=1.0.0\n","  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 50.9 MB/s \n","\u001b[?25hCollecting pytorch-lightning>=1.0.4\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[K     |████████████████████████████████| 813 kB 39.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.15.0)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (57.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from lightly) (2021.5.30)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.19.5)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.24.3)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightly) (0.10.0+cu102)\n","Collecting tqdm>=4.44\n","  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.23.0)\n","Collecting lightly-utils==0.0.1\n","  Downloading lightly_utils-0.0.1-py3-none-any.whl (6.3 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lightly-utils==0.0.1->lightly) (7.1.2)\n","Collecting omegaconf==2.1.*\n","  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (5.2.0)\n","Collecting PyYAML>=5.1.*\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 47.7 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 48.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (1.9.0+cu102)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 51.2 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 52.4 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (21.0)\n","Collecting tensorboard!=2.5.0,>=2.2.0\n","  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","\u001b[K     |████████████████████████████████| 10.6 MB 50.0 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 46.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.0.4->lightly) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (3.0.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.8.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.34.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.17.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.32.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.36.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.12.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (4.6.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning>=1.0.4->lightly) (3.7.4.3)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 51.1 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 42.3 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.4->lightly) (21.2.0)\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.0.4->lightly) (3.5.0)\n","Building wheels for collected packages: antlr4-python3-runtime, future\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=2e32fd93404d50df8bf1848bc48addce4e04ee6b0f817bf07219f425757ca713\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=62e5d44b390a16729bd75f7f197efd132ff2e24906b7c246fda984ac862492fd\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built antlr4-python3-runtime future\n","Installing collected packages: multidict, yarl, async-timeout, PyYAML, fsspec, antlr4-python3-runtime, aiohttp, tqdm, torchmetrics, tensorboard, pyDeprecate, omegaconf, future, pytorch-lightning, lightly-utils, hydra-core, lightly\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 antlr4-python3-runtime-4.8 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 hydra-core-1.1.0 lightly-1.1.15 lightly-utils-0.0.1 multidict-5.1.0 omegaconf-2.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.8 tensorboard-2.4.1 torchmetrics-0.4.1 tqdm-4.61.2 yarl-1.6.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reported-niger","executionInfo":{"status":"ok","timestamp":1626771181278,"user_tz":-540,"elapsed":4,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"98397deb-10af-4fda-c0f4-6c82bbda6fd3"},"source":["!nvidia-smi"],"id":"reported-niger","execution_count":3,"outputs":[{"output_type":"stream","text":["Tue Jul 20 08:52:56 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"major-purse","executionInfo":{"status":"ok","timestamp":1626771193532,"user_tz":-540,"elapsed":4157,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import lightly\n","import os"],"id":"major-purse","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"instructional-yesterday","executionInfo":{"status":"ok","timestamp":1626771193532,"user_tz":-540,"elapsed":3,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["num_workers = 2\n","batch_size = 256\n","seed = 1993\n","epochs = 50\n","input_size = 224\n","\n","# dimension of the embeddings\n","num_ftrs = 512\n","# dimension of the output of the prediction and projection heads\n","out_dim = proj_hidden_dim = 512\n","# the prediction head uses a bottleneck architecture\n","#pred_hidden_dim = 128\n","# use 2 layers in the projection head\n","num_mlp_layers = 2"],"id":"instructional-yesterday","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"lasting-addiction","executionInfo":{"status":"ok","timestamp":1626771193533,"user_tz":-540,"elapsed":3,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","\n","input_dir = '/content/drive/MyDrive/Colab Notebooks/atmacup/atmacup11/data/inputs/'\n","path_to_data = os.path.join(input_dir, 'photos')\n","model_dir = '/content/drive/MyDrive/Colab Notebooks/atmacup/atmacup11/data/model/'"],"id":"lasting-addiction","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sapphire-taiwan"},"source":["## DataLoader"],"id":"sapphire-taiwan"},{"cell_type":"code","metadata":{"id":"elegant-lesbian","executionInfo":{"status":"ok","timestamp":1626771236902,"user_tz":-540,"elapsed":43372,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# define the augmentations for self-supervised learning\n","collate_fn = lightly.data.ImageCollateFunction(\n","    input_size=input_size,\n","    # require invariance to flips and rotations\n","    hf_prob=0.5,\n","    vf_prob=0.5,\n","    rr_prob=0.5,\n","    # satellite images are all taken from the same height\n","    # so we use only slight random cropping\n","    min_scale=0.5,\n","    # use a weak color jitter for invariance w.r.t small color changes\n","    cj_prob=0.2,\n","    cj_bright=0.1,\n","    cj_contrast=0.1,\n","    cj_hue=0.1,\n","    cj_sat=0.1,\n",")\n","\n","# create a lightly dataset for training, since the augmentations are handled\n","# by the collate function, there is no need to apply additional ones here\n","dataset_train_simsiam = lightly.data.LightlyDataset(\n","    input_dir=path_to_data\n",")\n","\n","# create a dataloader for training\n","dataloader_train_simsiam = torch.utils.data.DataLoader(\n","    dataset_train_simsiam,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    drop_last=True,\n","    num_workers=num_workers\n",")\n","\n","# create a torchvision transformation for embedding the dataset after training\n","# here, we resize the images to match the input size during training and apply\n","# a normalization of the color channel based on statistics from imagenet\n","test_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((input_size, input_size)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(\n","        mean=lightly.data.collate.imagenet_normalize['mean'],\n","        std=lightly.data.collate.imagenet_normalize['std'],\n","    )\n","])\n","\n","\n","\n","# create a lightly dataset for embedding\n","dataset_test = lightly.data.LightlyDataset(\n","    input_dir=path_to_data,\n","    transform=test_transforms\n",")\n","\n","\n","\n","# create a dataloader for embedding\n","dataloader_test = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")"],"id":"elegant-lesbian","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"equivalent-apollo"},"source":["## Model"],"id":"equivalent-apollo"},{"cell_type":"code","metadata":{"id":"super-understanding","executionInfo":{"status":"ok","timestamp":1626771237729,"user_tz":-540,"elapsed":835,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# we use a pretrained resnet for this tutorial to speed\n","# up training time but you can also train one from scratch\n","# Do not use pretrained Model\n","resnet = torchvision.models.resnet18(pretrained=False)\n","backbone = nn.Sequential(*list(resnet.children())[:-1])\n","\n","# create the SimSiam model using the backbone from above\n","model = lightly.models.SimSiam(\n","    backbone,\n","    num_ftrs=num_ftrs,\n","#     proj_hidden_dim=pred_hidden_dim,\n","#     pred_hidden_dim=pred_hidden_dim,\n","#     out_dim=out_dim,\n","    num_mlp_layers=num_mlp_layers\n",")"],"id":"super-understanding","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"artificial-penguin"},"source":["## Loss / Optimizer"],"id":"artificial-penguin"},{"cell_type":"code","metadata":{"id":"enormous-calendar","executionInfo":{"status":"ok","timestamp":1626771237729,"user_tz":-540,"elapsed":2,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["# SimSiam uses a symmetric negative cosine similarity loss\n","criterion = lightly.loss.SymNegCosineSimilarityLoss()\n","\n","# scale the learning rate\n","lr = 0.05 * batch_size / 256\n","# use SGD with momentum and weight decay\n","optimizer = torch.optim.SGD(\n","    model.parameters(),\n","    lr=lr,\n","    momentum=0.9,\n","    weight_decay=5e-4\n",")"],"id":"enormous-calendar","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"above-emission","executionInfo":{"status":"ok","timestamp":1626779916086,"user_tz":-540,"elapsed":8678358,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"40f1a64c-96ea-466c-ad5e-a5d547aaa536"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","avg_loss = 0.\n","avg_output_std = 0.\n","for e in range(epochs):\n","\n","    for (x0, x1), _, _ in dataloader_train_simsiam:\n","\n","        # move images to the gpu\n","        x0 = x0.to(device)\n","        x1 = x1.to(device)\n","\n","        # run the model on both transforms of the images\n","        # the output of the simsiam model is a y containing the predictions\n","        # and projections for each input x\n","        y0, y1 = model(x0, x1)\n","\n","        # backpropagation\n","        loss = criterion(y0, y1)\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # calculate the per-dimension standard deviation of the outputs\n","        # we can use this later to check whether the embeddings are collapsing\n","        output, _ = y0\n","        output = output.detach()\n","        output = torch.nn.functional.normalize(output, dim=1)\n","\n","        output_std = torch.std(output, 0)\n","        output_std = output_std.mean()\n","\n","        # use moving averages to track the loss and standard deviation\n","        w = 0.9\n","        avg_loss = w * avg_loss + (1 - w) * loss.item()\n","        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n","\n","    # the level of collapse is large if the standard deviation of the l2\n","    # normalized output is much smaller than 1 / sqrt(dim)\n","    collapse_level = max(0., 1 - math.sqrt(out_dim) * avg_output_std)\n","    # print intermediate results\n","    print(f'[Epoch {e:3d}] '\n","        f'Loss = {avg_loss:.2f} | '\n","        f'Collapse Level: {collapse_level:.2f} / 1.00')"],"id":"above-emission","execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch   0] Loss = -0.54 | Collapse Level: 0.55 / 1.00\n","[Epoch   1] Loss = -0.81 | Collapse Level: 0.54 / 1.00\n","[Epoch   2] Loss = -0.84 | Collapse Level: 0.55 / 1.00\n","[Epoch   3] Loss = -0.85 | Collapse Level: 0.55 / 1.00\n","[Epoch   4] Loss = -0.87 | Collapse Level: 0.55 / 1.00\n","[Epoch   5] Loss = -0.89 | Collapse Level: 0.55 / 1.00\n","[Epoch   6] Loss = -0.89 | Collapse Level: 0.56 / 1.00\n","[Epoch   7] Loss = -0.90 | Collapse Level: 0.56 / 1.00\n","[Epoch   8] Loss = -0.90 | Collapse Level: 0.56 / 1.00\n","[Epoch   9] Loss = -0.90 | Collapse Level: 0.56 / 1.00\n","[Epoch  10] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  11] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  12] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  13] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  14] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  15] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  16] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  17] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  18] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  19] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  20] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  21] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  22] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  23] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  24] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  25] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  26] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  27] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  28] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  29] Loss = -0.91 | Collapse Level: 0.57 / 1.00\n","[Epoch  30] Loss = -0.91 | Collapse Level: 0.57 / 1.00\n","[Epoch  31] Loss = -0.90 | Collapse Level: 0.56 / 1.00\n","[Epoch  32] Loss = -0.91 | Collapse Level: 0.56 / 1.00\n","[Epoch  33] Loss = -0.91 | Collapse Level: 0.57 / 1.00\n","[Epoch  34] Loss = -0.91 | Collapse Level: 0.57 / 1.00\n","[Epoch  35] Loss = -0.91 | Collapse Level: 0.57 / 1.00\n","[Epoch  36] Loss = -0.91 | Collapse Level: 0.58 / 1.00\n","[Epoch  37] Loss = -0.90 | Collapse Level: 0.59 / 1.00\n","[Epoch  38] Loss = -0.91 | Collapse Level: 0.58 / 1.00\n","[Epoch  39] Loss = -0.91 | Collapse Level: 0.58 / 1.00\n","[Epoch  40] Loss = -0.92 | Collapse Level: 0.59 / 1.00\n","[Epoch  41] Loss = -0.92 | Collapse Level: 0.58 / 1.00\n","[Epoch  42] Loss = -0.91 | Collapse Level: 0.58 / 1.00\n","[Epoch  43] Loss = -0.90 | Collapse Level: 0.58 / 1.00\n","[Epoch  44] Loss = -0.89 | Collapse Level: 0.58 / 1.00\n","[Epoch  45] Loss = -0.90 | Collapse Level: 0.59 / 1.00\n","[Epoch  46] Loss = -0.90 | Collapse Level: 0.59 / 1.00\n","[Epoch  47] Loss = -0.90 | Collapse Level: 0.59 / 1.00\n","[Epoch  48] Loss = -0.91 | Collapse Level: 0.59 / 1.00\n","[Epoch  49] Loss = -0.90 | Collapse Level: 0.59 / 1.00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"municipal-situation","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626779916086,"user_tz":-540,"elapsed":9,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"a7b35ddc-e948-42ad-d50d-ac056c7b413b"},"source":["from torchsummary import summary\n","summary(model, (3,224,224))"],"id":"municipal-situation","execution_count":11,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                 [-1, 2048]       1,050,624\n","      BatchNorm1d-69                 [-1, 2048]           4,096\n","             ReLU-70                 [-1, 2048]               0\n","           Linear-71                 [-1, 2048]       4,196,352\n","      BatchNorm1d-72                 [-1, 2048]           4,096\n","           Linear-73                  [-1, 512]       1,049,088\n","      BatchNorm1d-74                  [-1, 512]           1,024\n","             ReLU-75                  [-1, 512]               0\n","           Linear-76                 [-1, 2048]       1,050,624\n","================================================================\n","Total params: 18,532,416\n","Trainable params: 18,532,416\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.89\n","Params size (MB): 70.70\n","Estimated Total Size (MB): 134.16\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"expected-magic","executionInfo":{"status":"ok","timestamp":1626779916566,"user_tz":-540,"elapsed":482,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["torch.save(model.state_dict(), os.path.join(model_dir,'simsiam_res18_256.pth'))"],"id":"expected-magic","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"circular-discussion","executionInfo":{"status":"ok","timestamp":1626781070230,"user_tz":-540,"elapsed":325,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}}},"source":["test = model.load_state_dict(torch.load(os.path.join(model_dir,'simsiam_res18_256.pth')))"],"id":"circular-discussion","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"80-XW7gKwhuZ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"error","timestamp":1626781211567,"user_tz":-540,"elapsed":3,"user":{"displayName":"おねです","photoUrl":"","userId":"09513891075447620928"}},"outputId":"6acbdeff-1398-456b-a648-79991092b300"},"source":["from torchsummary import summary\n","#model = resnet18(pretrained=False)\n","resnet = resnet18(pretrained=False)\n","backbone = nn.Sequential(*list(resnet.children())[:-1])\n","model = lightly.models.SimSiam(\n","    backbone,\n","    num_ftrs=num_ftrs,\n","#     proj_hidden_dim=pred_hidden_dim,\n","#     pred_hidden_dim=pred_hidden_dim,\n","#     out_dim=out_dim,\n","    num_mlp_layers=num_mlp_layers\n",")\n","model.load_state_dict(torch.load(os.path.join(model_dir,'simsiam_res18_256.pth')))\n","model = model.backbone\n","model.add_module('flatten', nn.Flatten())\n","model.add_module('fc', nn.Linear(in_features=512, out_features=1, bias=True))\n","DEVICE = torch.device(\"cuda\")\n","model.to(DEVICE)\n","summary(model, (3,224,224))"],"id":"80-XW7gKwhuZ","execution_count":17,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-5f32a8578808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'to'"]}]},{"cell_type":"code","metadata":{"id":"dJHhJ21ptjtd"},"source":[""],"id":"dJHhJ21ptjtd","execution_count":null,"outputs":[]}]}